@inproceedings{ramirez2025cascade,
  title={Cascade: Human-in-the-Loop Shortcomings Can Increase the Risk of Failures in Recommender Systems},
  author={Ramirez, Tuesday (Claudia)},
  booktitle={FAccTRec Workshop at ACM RecSys},
  year={2025},
  arxiv={2509.20099},
  selected={true},
  abstract={This paper examines how human-in-the-loop systems in recommender systems can paradoxically increase failure risks through cascade effects, particularly in high-stakes domains.},
  abbr={RecSys}
}

@techreport{ramirez2024ailuminate,
  title={AILuminate v1.0: AI Risk \& Reliability / Generative AI Safety Benchmark},
  author={Ramirez, Tuesday (Claudia) and MLCommons AI Safety Working Group},
  institution={MLCommons},
  year={2024},
  arxiv={2404.03555},
  selected={true},
  abstract={Comprehensive benchmark for evaluating AI risk and reliability in generative AI systems, establishing industry-standard metrics for safety evaluation.},
  abbr={MLCommons},
  html={https://mlcommons.org/}
}

@inproceedings{ramirez2024aspirational,
  title={Aspirational Game Play: Improving Patient Care, Mental Hygiene, and Bad Habits With AI-Powered Video Games},
  author={Ramirez, Tuesday (Claudia)},
  booktitle={ACM SIGGRAPH 2024 Frontiers},
  year={2024},
  selected={true},
  abstract={Explores the intersection of therapeutic design, AI, and gaming to address mental health and behavioral change through aspirational gameplay mechanics.},
  abbr={SIGGRAPH}
}

@misc{ramirez2024ares,
  title={Agentic Reliability Evaluation Standard (ARES)},
  author={Ramirez, Tuesday (Claudia) and MLCommons Agentic AI Working Group},
  year={2024},
  publisher={MLCommons},
  selected={true},
  abstract={Industry-standard framework for evaluating reliability, safety, and maturity of agentic AI systems, including cascade failure analysis and statefulness evaluation.},
  abbr={MLCommons}
}

@dataset{ramirez2024jailbreak,
  title={MLCommons Security Jailbreak Benchmark v0.5},
  author={Ramirez, Tuesday (Claudia) and MLCommons Security Working Group},
  year={2024},
  publisher={MLCommons},
  selected={true},
  abstract={Introduction of the Resilience Gap metric for evaluating AI system robustness against adversarial attacks and jailbreak attempts.},
  abbr={MLCommons},
  note={Informed ISO/IEC 42001 standards}
}

@dataset{ramirez2024t2i,
  title={Text-to-Image Safety Benchmark: Cross-Cultural Ground Truth Annotations},
  author={Ramirez, Tuesday (Claudia)},
  year={2024},
  publisher={Humane Intelligence},
  abstract={800+ cross-cultural ground truth annotations for generative safety evaluation, with trauma-informed annotation protocols.},
  abbr={HI}
}

@misc{ramirez2024scai,
  title={SCAI Risk Framework: Seemingly Conscious AI and Epistemic Coercion},
  author={Ramirez, Tuesday (Claudia)},
  year={2024},
  publisher={ARTIFEX Labs},
  selected={true},
  abstract={Clinical diagnostic framework for AI behavioral pathologies, introducing concepts of SCAI risk, epistemic coercion, and dissociative reasoning in large language models.},
  abbr={ARTIFEX}
}

@misc{ramirez2024aei,
  title={American Emotional Infrastructure (AEI): Quantum-Inspired Metrics for National Socio-Technical Resilience},
  author={Ramirez, Tuesday (Claudia)},
  year={2024},
  publisher={ARTIFEX Labs},
  abstract={Treating national affect and socio-technical stacks as critical infrastructure with quantum-inspired metrics for stress, trust, and polarization.},
  abbr={ARTIFEX}
}

@misc{ramirez2024foretells,
  title={FORETELLS \& ADA: Multi-Agent Safety Architecture for Post-AGI Systems},
  author={Ramirez, Tuesday (Claudia)},
  year={2024},
  publisher={ARTIFEX Labs},
  abstract={Novel multi-agent architecture designed for safety and reliability in post-AGI systems, incorporating therapeutic interpretability and cascade failure prevention.},
  abbr={ARTIFEX}
}
