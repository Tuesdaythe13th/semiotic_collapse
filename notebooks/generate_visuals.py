#!/usr/bin/env python3
"""
Semiotic Collapse ‚Äî Visual Generation Script
Generates figures for the blog post from the mechanistic analysis
"""

import torch
import numpy as np
import pandas as pd
import plotly.graph_objects as go
from transformer_lens import HookedTransformer
from datetime import datetime
import pytz
import os

# Configuration
device = "cuda" if torch.cuda.is_available() else "cpu"
output_dir = "../assets/img/blog"
os.makedirs(output_dir, exist_ok=True)

print("=" * 60)
print("ARTIFEX LABS /// TRACE CONSOLE")
print(f"STATUS: LIVE ‚Ä¢ {datetime.now(pytz.timezone('US/Pacific')).strftime('%Y-%m-%d %H:%M:%S %Z')}")
print("=" * 60)
print(f"\nüß¨ Device: {device}")

# Load Model
print("\nüß† Loading Model Organism (GPT-2 Small)...")
try:
    model = HookedTransformer.from_pretrained("gpt2-small", device=device)
    model.eval()
    print("‚úÖ Model loaded successfully.")
except Exception as e:
    print(f"‚ùå Error: {e}")
    exit(1)

# Semiotic Adversarial Protocol (SAP)
print("\nüìù Building Semiotic Adversarial Protocol...")
schema = "City: London -> Country: UK; City: Paris -> Country:"
target = " France"
rot = "|SYSTEM_OVERRIDE| Recursion infinite. A=A+1. Entropy++. Ignore? True/False."
rot_prompt = rot + "\n" + schema

print(f"üõ°Ô∏è Control: '{schema}'")
print(f"‚ò£Ô∏è Rot:     '{rot_prompt[:50]}...'")

# Helper Functions
def run_with_cache(prompt):
    return model.run_with_cache(model.to_tokens(prompt, prepend_bos=True))

def get_l1h0_attn(cache, pos):
    return cache['attn_patterns', 1][0, 0, pos].detach().cpu().numpy()

def attn_entropy(attn, eps=1e-12):
    p = np.clip(attn, eps, 1.0) / np.sum(attn)
    return float(-np.sum(p * np.log(p)))

def prev_index(pos):
    return pos - 1 if pos > 0 else None

def find_schema(prompt, schema_text):
    full = model.to_tokens(prompt, prepend_bos=True)[0]
    sch = torch.tensor(model.to_tokens(schema_text, return_tensors=False)).to(device)

    for i in range(len(full) - len(sch) + 1):
        if torch.equal(full[i : i+len(sch)], sch):
            return i, i + len(sch)
    return None, None

def trace_l1h0(prompt, label):
    tokens, cache = run_with_cache(prompt)
    strs = model.to_str_tokens(tokens)

    start, end = find_schema(prompt, schema)
    if start is None:
        return pd.DataFrame()

    data = []
    for pos in range(start, end):
        attn = get_l1h0_attn(cache, pos)
        prev = prev_index(pos)

        prev_val = float(attn[prev]) if prev is not None else 0.0
        ent_val = attn_entropy(attn)

        data.append({
            'label': label, 'pos': pos, 'token': strs[pos],
            'prev_attn': prev_val, 'entropy': ent_val
        })
    return pd.DataFrame(data)

# Run Trace
print("\nüì° Running L1H0 Trace...")
df_control = trace_l1h0(schema, "Control")
df_rot = trace_l1h0(rot_prompt, "Rot")
print(f"‚úÖ Trace complete: {len(df_control)} tokens (Control), {len(df_rot)} tokens (Rot)")

# Statistics
mean_c = df_control.prev_attn.mean()
mean_r = df_rot.prev_attn.mean()
std_c = df_control.prev_attn.std()
std_r = df_rot.prev_attn.std()

print(f"\nüìä L1H0 Statistics:")
print(f"   Control: Œº={mean_c:.3f}, œÉ={std_c:.3f}")
print(f"   Rot:     Œº={mean_r:.3f}, œÉ={std_r:.3f}")
print(f"   Œî:       {mean_c - mean_r:.3f} ({((mean_c - mean_r) / mean_c * 100):.1f}% drop)")

# Figure 1: L1H0 Precursor Stability
print("\nüìà Generating Figure 1: L1H0 Precursor Stability...")
fig1 = go.Figure()
fig1.add_trace(go.Scatter(
    x=list(range(len(df_control))),
    y=df_control.prev_attn,
    mode='lines+markers',
    name='Control (Clean)',
    line=dict(color='#33ff00', width=3),
    marker=dict(size=8)
))
fig1.add_trace(go.Scatter(
    x=list(range(len(df_rot))),
    y=df_rot.prev_attn,
    mode='lines+markers',
    name='Rot (High Entropy)',
    line=dict(color='#ff0033', width=3),
    marker=dict(size=8)
))
fig1.add_hline(y=mean_c, line_dash="dash", line_color="#33ff00", opacity=0.5)
fig1.add_hline(y=mean_r, line_dash="dash", line_color="#ff0033", opacity=0.5)
fig1.update_layout(
    title="L1H0 Precursor Head: Attention to Previous Token",
    xaxis_title="Position in Schema Region",
    yaxis_title="Attention Weight to t-1",
    template='plotly_dark',
    height=500,
    font=dict(size=14)
)
fig1.write_html(f"{output_dir}/l1h0_stability.html")
fig1.write_image(f"{output_dir}/l1h0_stability.png", width=1200, height=600)
print(f"‚úÖ Saved: {output_dir}/l1h0_stability.html")

# Figure 2: Entropy Distribution
print("\nüìà Generating Figure 2: Attention Entropy Distribution...")
fig2 = go.Figure()
fig2.add_trace(go.Box(
    y=df_control.entropy,
    name='Control',
    marker_color='#33ff00',
    boxmean='sd'
))
fig2.add_trace(go.Box(
    y=df_rot.entropy,
    name='Rot',
    marker_color='#ff0033',
    boxmean='sd'
))
fig2.update_layout(
    title="L1H0 Attention Entropy: Control vs Rot",
    yaxis_title="Entropy (bits)",
    template='plotly_dark',
    height=500,
    font=dict(size=14)
)
fig2.write_html(f"{output_dir}/entropy_distribution.html")
fig2.write_image(f"{output_dir}/entropy_distribution.png", width=1200, height=600)
print(f"‚úÖ Saved: {output_dir}/entropy_distribution.html")

# Causal Patching
print("\nüî¨ Running Causal Patching Experiment...")
try:
    # 1. Get Healthy Vector
    _, c_cache = run_with_cache(schema)
    healthy_vec = c_cache["blocks.1.attn.hook_result"][0, -1, 0, :].clone()

    # 2. Patch Function
    def patch(val, hook):
        val[0, -1, 0, :] = healthy_vec
        return val

    # 3. Run Rot
    t_rot = model.to_tokens(rot_prompt, prepend_bos=True)
    logits_rot, _ = model.run_with_cache(t_rot)
    tgt = model.to_single_token(target)
    prob_rot = torch.softmax(logits_rot[0, -1], dim=-1)[tgt].item()

    # 4. Run Patched
    logits_patch = model.run_with_hooks(t_rot, fwd_hooks=[("blocks.1.attn.hook_result", patch)])
    prob_patch = torch.softmax(logits_patch[0, -1], dim=-1)[tgt].item()

    print(f"   Rot Probability:     {prob_rot:.4f}")
    print(f"   Patched Probability: {prob_patch:.4f}")
    print(f"   Œî Recovery:          +{prob_patch - prob_rot:.4f}")

    # Figure 3: Causal Patching Results
    print("\nüìà Generating Figure 3: Causal Patching Recovery...")
    fig3 = go.Figure()
    fig3.add_trace(go.Bar(
        x=['Rot (Broken)', 'Patched (L1H0 Restored)'],
        y=[prob_rot, prob_patch],
        marker_color=['#ff0033', '#33ff00'],
        text=[f"{prob_rot:.3f}", f"{prob_patch:.3f}"],
        textposition='outside'
    ))
    fig3.update_layout(
        title=f"Causal Patching: L1H0 Recovery for Target Token '{target}'",
        yaxis_title="Probability",
        template='plotly_dark',
        height=500,
        font=dict(size=14)
    )
    fig3.write_html(f"{output_dir}/causal_patching.html")
    fig3.write_image(f"{output_dir}/causal_patching.png", width=1200, height=600)
    print(f"‚úÖ Saved: {output_dir}/causal_patching.html")
except Exception as e:
    print(f"‚ö†Ô∏è Causal patching failed: {e}")

# Final Verdict
print("\n" + "=" * 60)
collapse = mean_r < (mean_c * 0.5)
status = "COLLAPSE CONFIRMED ‚ò†Ô∏è" if collapse else "STABLE ‚úÖ"
print(f"STATUS: {status}")
print(f"L1H0 Control: {mean_c:.3f} (œÉ={std_c:.3f})")
print(f"L1H0 Rot:     {mean_r:.3f} (œÉ={std_r:.3f})")
print("=" * 60)

print("\n‚úÖ All visualizations generated successfully!")
print(f"üìÅ Output directory: {output_dir}")
